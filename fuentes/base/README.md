# Fuentes Base - Plantilla Multi-Fuente de Datos

Plantilla base reutilizable en Python para ingesta de datos desde m√∫ltiples tipos de fuentes: APIs REST, scraping web (est√°tico y din√°mico con JavaScript), descarga y parseo de archivos (PDF, XLSX, CSV), con almacenamiento en MariaDB.

## Caracter√≠sticas

- üåê **Multi-Fuente**: Soporte para APIs REST, scraping web est√°tico/din√°mico, descarga de archivos
- üìÑ **Multi-Formato**: Parseo de JSON, PDF, XLSX, CSV, HTML
- üèóÔ∏è **Arquitectura Modular**: Extractores y parsers separados y extensibles
- üîÑ **Retry Logic**: L√≥gica de reintento con backoff exponencial
- üì¶ **Append-Only Storage**: Estrategia de almacenamiento que preserva auditor√≠a completa
- üê≥ **Docker-Ready**: Completamente contenedorizado
- ‚öôÔ∏è **Type-Safe Config**: Configuraci√≥n con pydantic-settings
- üìä **MariaDB 10.11**: Almacenamiento confiable con soporte JSON
- üéØ **Extensible**: F√°cil agregar nuevos extractores y parsers

## Arquitectura

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              Fuentes de Datos                            ‚îÇ
‚îÇ  (APIs REST, P√°ginas Web, Archivos PDF/XLSX/CSV)        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                           ‚îÇ
                           ‚Üì
            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
            ‚îÇ    main.py Orchestrator      ‚îÇ
            ‚îÇ  (Pipeline configurable)     ‚îÇ
            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚Üô   ‚Üì   ‚Üò
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇExtractors‚îÇ ‚îÇParsers   ‚îÇ ‚îÇRepositories  ‚îÇ
        ‚îÇ(multi-   ‚îÇ ‚îÇ(multi-   ‚îÇ ‚îÇ(Database)    ‚îÇ
        ‚îÇsource)   ‚îÇ ‚îÇformat)   ‚îÇ ‚îÇ              ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                           ‚îÇ
                           ‚Üì
            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
            ‚îÇ    MariaDB (10.11)           ‚îÇ
            ‚îÇ   raw_data (auditor√≠a)       ‚îÇ
            ‚îÇ   extracted_data (parsed)    ‚îÇ
            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## Tipos de Extractores Soportados

### 1. API REST (`api_rest`)
Extracci√≥n desde APIs REST con retry logic y manejo de JSON.

**Ejemplo**:
```python
from src.extractors.api_rest import APIRestExtractor

extractor = APIRestExtractor(urls=["https://api.example.com/data"])
results = extractor.extract()
```

### 2. Web Scraping Est√°tico (`web_static`)
Scraping de p√°ginas HTML server-side rendered usando BeautifulSoup.

**Ejemplo**:
```python
from src.extractors.web_static import WebStaticExtractor

extractor = WebStaticExtractor(urls=["https://example.com/page"])
results = extractor.extract()
```

### 3. Web Scraping Din√°mico (`web_dynamic`)
Scraping de p√°ginas con JavaScript usando Playwright (Chrome headless).

**Ejemplo**:
```python
from src.extractors.web_dynamic import WebDynamicExtractor

extractor = WebDynamicExtractor(
    urls=["https://example.com/dynamic"],
    wait_selector="div.content"
)
results = extractor.extract()
```

### 4. Descarga de Archivos (`file_download`)
Descarga de archivos (PDF, XLSX, CSV) desde URLs o S3.

**Ejemplo**:
```python
from src.extractors.file_download import FileDownloadExtractor

extractor = FileDownloadExtractor(
    urls=["https://example.com/file.pdf"],
    download_dir="downloads/"
)
results = extractor.extract()
```

## Tipos de Parsers Soportados

### 1. JSON Parser
Parseo y transformaci√≥n de datos JSON.

### 2. PDF Parser
Extracci√≥n de texto y tablas de PDFs usando pdfplumber.

### 3. XLSX Parser
Lectura de archivos Excel con openpyxl.

### 4. CSV Parser
Parseo de archivos CSV.

### 5. HTML Parser
Extracci√≥n de datos desde HTML con BeautifulSoup.

## Quick Start

### Prerequisitos

- Docker y Docker Compose instalados
- Python 3.12+ (para desarrollo local)
- Git

### Setup

1. **Clonar o copiar esta plantilla**
   ```bash
   cd fuentes/
   cp -r base mi-nueva-fuente
   cd mi-nueva-fuente
   ```

2. **Crear archivo de configuraci√≥n**
   ```bash
   cp .env.example .env
   ```

3. **Configurar tu fuente de datos**

   Editar `.env` y configurar seg√∫n tu tipo de fuente:

   **Para API REST**:
   ```env
   SOURCE_TYPE=api_rest
   API_URL_1=https://api.example.com/v1/data
   API_URL_2=https://api.example.com/v1/users
   ```

   **Para scraping web**:
   ```env
   SOURCE_TYPE=web_static
   WEB_URL_1=https://example.com/page1
   WEB_URL_2=https://example.com/page2
   ```

4. **Iniciar la base de datos**
   ```bash
   docker-compose up -d base_db
   ```

   Esperar que la base de datos est√© saludable (~30 segundos):
   ```bash
   docker-compose ps
   ```

5. **Ejecutar la ingesta**
   ```bash
   docker-compose run --rm base_app
   ```

## Estructura del Proyecto

```
fuentes/base/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ main.py                    # Orquestador principal
‚îÇ   ‚îú‚îÄ‚îÄ settings.py                # Configuraci√≥n con pydantic
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ core/                      # Utilidades core
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ http_client.py         # Cliente HTTP con retries
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ logging.py             # Setup de logging
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ database.py            # Gestor de base de datos
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ extractors/                # Extractores por tipo
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base.py                # BaseExtractor (clase abstracta)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api_rest.py            # Extractor para APIs REST
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ web_static.py          # Scraping HTML est√°tico
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ web_dynamic.py         # Scraping JS din√°mico (Playwright)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ file_download.py       # Descarga de archivos
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ parsers/                   # Parsers por formato
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base.py                # BaseParser (clase abstracta)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ json_parser.py         # Parser JSON
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pdf_parser.py          # Parser PDF (pdfplumber)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ xlsx_parser.py         # Parser XLSX (openpyxl)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ csv_parser.py          # Parser CSV
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ html_parser.py         # Parser HTML (BeautifulSoup)
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ repositories/              # Repositorios de base de datos
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base.py                # BaseRepository
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ raw_data.py            # RawDataRepository
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ utils/                     # Utilidades
‚îÇ       ‚îú‚îÄ‚îÄ retry.py               # Decorador de retry
‚îÇ       ‚îî‚îÄ‚îÄ helpers.py             # Helper functions
‚îÇ
‚îú‚îÄ‚îÄ db/
‚îÇ   ‚îú‚îÄ‚îÄ init.sql                   # Schema inicial
‚îÇ   ‚îî‚îÄ‚îÄ migrations/                # Migraciones de BD
‚îÇ
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îú‚îÄ‚îÄ ARCHITECTURE.md            # Documentaci√≥n de arquitectura
‚îÇ   ‚îú‚îÄ‚îÄ EXTRACTORS.md              # Gu√≠a de extractores
‚îÇ   ‚îú‚îÄ‚îÄ PARSERS.md                 # Gu√≠a de parsers
‚îÇ   ‚îî‚îÄ‚îÄ EXAMPLES.md                # Ejemplos de uso
‚îÇ
‚îú‚îÄ‚îÄ examples/                      # Ejemplos completos
‚îÇ   ‚îú‚îÄ‚îÄ rest_api/                  # Ejemplo con API REST
‚îÇ   ‚îú‚îÄ‚îÄ web_scraping/              # Ejemplo con scraping
‚îÇ   ‚îî‚îÄ‚îÄ file_processing/           # Ejemplo con archivos
‚îÇ
‚îú‚îÄ‚îÄ .env.example                   # Template de configuraci√≥n
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ docker-compose.yml             # Orquestaci√≥n de servicios
‚îú‚îÄ‚îÄ Dockerfile                     # Imagen de la aplicaci√≥n
‚îú‚îÄ‚îÄ pyproject.toml                 # Dependencias Python
‚îú‚îÄ‚îÄ README.md                      # Este archivo
‚îî‚îÄ‚îÄ CLAUDE.md                      # Gu√≠a de desarrollo
```

## Uso

### Ejecuci√≥n Manual

Ejecutar una ingesta √∫nica:
```bash
docker-compose run --rm base_app
```

### Programaci√≥n con Cron

Agregar a crontab del sistema para ejecuci√≥n peri√≥dica:

```bash
# Cada hora
0 * * * * cd /path/to/fuentes/base && docker-compose run --rm base_app

# Cada 6 horas
0 */6 * * * cd /path/to/fuentes/base && docker-compose run --rm base_app

# Diario a las 2 AM
0 2 * * * cd /path/to/fuentes/base && docker-compose run --rm base_app
```

### Ver Datos

Conectarse a la base de datos:

```bash
docker-compose exec base_db mysql -u base_user -pbase_password fuentes_base
```

Queries de ejemplo:
```sql
-- Ver todos los datos extra√≠dos
SELECT * FROM raw_data ORDER BY fetched_at DESC LIMIT 10;

-- Ver extracciones exitosas √∫nicamente
SELECT * FROM successful_extractions LIMIT 10;

-- Ver √∫ltima extracci√≥n por URL
SELECT * FROM latest_extractions;

-- Contar extracciones por fuente
SELECT source_url, COUNT(*) as count
FROM raw_data
GROUP BY source_url;
```

## Desarrollo

### Desarrollo Local sin Docker

1. **Instalar uv** (si no est√° instalado):
   ```bash
   curl -LsSf https://astral.sh/uv/install.sh | sh
   ```

2. **Crear entorno virtual e instalar dependencias**:
   ```bash
   uv sync
   ```

3. **Activar entorno virtual**:
   ```bash
   source .venv/bin/activate  # Unix/macOS
   ```

4. **Ejecutar la aplicaci√≥n**:
   ```bash
   python -m src.main
   ```

### Agregar Nuevo Extractor

1. Crear archivo en `src/extractors/mi_extractor.py`
2. Heredar de `BaseExtractor`
3. Implementar m√©todo `extract()`
4. Registrar en `settings.py` si es necesario

**Ejemplo**:
```python
from src.extractors.base import BaseExtractor

class MiExtractor(BaseExtractor):
    def extract(self) -> list[dict]:
        # Tu l√≥gica aqu√≠
        return results
```

### Agregar Nuevo Parser

1. Crear archivo en `src/parsers/mi_parser.py`
2. Heredar de `BaseParser`
3. Implementar m√©todo `parse()`
4. Registrar en configuraci√≥n

**Ejemplo**:
```python
from src.parsers.base import BaseParser

class MiParser(BaseParser):
    def parse(self, data: Any) -> dict:
        # Tu l√≥gica aqu√≠
        return parsed_data
```

## Despliegue en Producci√≥n

Para despliegue en producci√≥n:

1. **Actualizar `.env` con credenciales de producci√≥n**:
   ```env
   DB_HOST=production.db.hostname
   DB_USER=production_user
   DB_PASSWORD=secure_password
   ```

2. **Build y run** (servicio de BD no necesario si usas BD externa):
   ```bash
   docker build -t fuentes-base:latest .
   docker run --env-file .env fuentes-base:latest
   ```

3. **Configurar cron** en el servidor para ejecuci√≥n peri√≥dica

## Patrones y Convenciones

### Convenciones de Nombres
- **Base de datos**: `snake_case` (raw_data, source_url)
- **Archivos Python**: `snake_case` (http_client.py, api_rest.py)
- **Clases Python**: `PascalCase` (BaseExtractor, APIRestExtractor)
- **Constantes**: `SCREAMING_SNAKE_CASE` (MAX_RETRIES)

### Estrategia Append-Only
- Nunca UPDATE o DELETE de registros hist√≥ricos
- Cada extracci√≥n crea nueva fila en `raw_data`
- Preserva auditor√≠a completa de todas las operaciones

### Manejo de Errores
- Errores por URL no detienen la ejecuci√≥n completa
- Errores de conexi√≥n a BD fallan r√°pido
- Todos los errores loggeados con niveles apropiados
- Operaciones batch trackean fallos separadamente

## Casos de Uso

Perfecto para:
- üìä Iniciativas de datos abiertos
- üèõÔ∏è Consumo de APIs gubernamentales
- üìà Recolecci√≥n de datos financieros
- üåê Agregaci√≥n de datos multi-fuente
- üîÑ Sincronizaci√≥n regular de datos
- üì¶ Construcci√≥n de data lakes desde APIs/web/archivos
- ‚ö° Extracci√≥n de datos de la industria energ√©tica

## Documentaci√≥n Adicional

- [ARCHITECTURE.md](docs/ARCHITECTURE.md) - Documentaci√≥n detallada de arquitectura
- [EXTRACTORS.md](docs/EXTRACTORS.md) - Gu√≠a completa de extractores
- [PARSERS.md](docs/PARSERS.md) - Gu√≠a completa de parsers
- [EXAMPLES.md](docs/EXAMPLES.md) - Ejemplos pr√°cticos de uso

## Licencia

*(Agregar licencia aqu√≠)*

## Contribuciones

*(Agregar gu√≠as de contribuci√≥n aqu√≠)*
